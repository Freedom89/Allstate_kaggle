<!DOCTYPE html>
<html>

<head>

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>index</title>


<style type="text/css">
body {
  font-family: Helvetica, arial, sans-serif;
  font-size: 14px;
  line-height: 1.6;
  padding-top: 10px;
  padding-bottom: 10px;
  background-color: white;
  padding: 30px; }

body > *:first-child {
  margin-top: 0 !important; }
body > *:last-child {
  margin-bottom: 0 !important; }

a {
  color: #4183C4; }
a.absent {
  color: #cc0000; }
a.anchor {
  display: block;
  padding-left: 30px;
  margin-left: -30px;
  cursor: pointer;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0; }

h1, h2, h3, h4, h5, h6 {
  margin: 20px 0 10px;
  padding: 0;
  font-weight: bold;
  -webkit-font-smoothing: antialiased;
  cursor: text;
  position: relative; }

h1:hover a.anchor, h2:hover a.anchor, h3:hover a.anchor, h4:hover a.anchor, h5:hover a.anchor, h6:hover a.anchor {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA09pVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMy1jMDExIDY2LjE0NTY2MSwgMjAxMi8wMi8wNi0xNDo1NjoyNyAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNiAoMTMuMCAyMDEyMDMwNS5tLjQxNSAyMDEyLzAzLzA1OjIxOjAwOjAwKSAgKE1hY2ludG9zaCkiIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OUM2NjlDQjI4ODBGMTFFMTg1ODlEODNERDJBRjUwQTQiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OUM2NjlDQjM4ODBGMTFFMTg1ODlEODNERDJBRjUwQTQiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo5QzY2OUNCMDg4MEYxMUUxODU4OUQ4M0REMkFGNTBBNCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo5QzY2OUNCMTg4MEYxMUUxODU4OUQ4M0REMkFGNTBBNCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PsQhXeAAAABfSURBVHjaYvz//z8DJYCRUgMYQAbAMBQIAvEqkBQWXI6sHqwHiwG70TTBxGaiWwjCTGgOUgJiF1J8wMRAIUA34B4Q76HUBelAfJYSA0CuMIEaRP8wGIkGMA54bgQIMACAmkXJi0hKJQAAAABJRU5ErkJggg==) no-repeat 10px center;
  text-decoration: none; }

h1 tt, h1 code {
  font-size: inherit; }

h2 tt, h2 code {
  font-size: inherit; }

h3 tt, h3 code {
  font-size: inherit; }

h4 tt, h4 code {
  font-size: inherit; }

h5 tt, h5 code {
  font-size: inherit; }

h6 tt, h6 code {
  font-size: inherit; }

h1 {
  font-size: 28px;
  color: black; }

h2 {
  font-size: 24px;
  border-bottom: 1px solid #cccccc;
  color: black; }

h3 {
  font-size: 18px; }

h4 {
  font-size: 16px; }

h5 {
  font-size: 14px; }

h6 {
  color: #777777;
  font-size: 14px; }

p, blockquote, ul, ol, dl, li, table, pre {
  margin: 15px 0; }

hr {
  background: transparent url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAYAAAAECAYAAACtBE5DAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAyJpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNSBNYWNpbnRvc2giIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OENDRjNBN0E2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OENDRjNBN0I2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo4Q0NGM0E3ODY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo4Q0NGM0E3OTY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PqqezsUAAAAfSURBVHjaYmRABcYwBiM2QSA4y4hNEKYDQxAEAAIMAHNGAzhkPOlYAAAAAElFTkSuQmCC) repeat-x 0 0;
  border: 0 none;
  color: #cccccc;
  height: 4px;
  padding: 0;
}

body > h2:first-child {
  margin-top: 0;
  padding-top: 0; }
body > h1:first-child {
  margin-top: 0;
  padding-top: 0; }
  body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0; }
body > h3:first-child, body > h4:first-child, body > h5:first-child, body > h6:first-child {
  margin-top: 0;
  padding-top: 0; }

a:first-child h1, a:first-child h2, a:first-child h3, a:first-child h4, a:first-child h5, a:first-child h6 {
  margin-top: 0;
  padding-top: 0; }

h1 p, h2 p, h3 p, h4 p, h5 p, h6 p {
  margin-top: 0; }

li p.first {
  display: inline-block; }
li {
  margin: 0; }
ul, ol {
  padding-left: 30px; }

ul :first-child, ol :first-child {
  margin-top: 0; }

dl {
  padding: 0; }
  dl dt {
    font-size: 14px;
    font-weight: bold;
    font-style: italic;
    padding: 0;
    margin: 15px 0 5px; }
    dl dt:first-child {
      padding: 0; }
    dl dt > :first-child {
      margin-top: 0; }
    dl dt > :last-child {
      margin-bottom: 0; }
  dl dd {
    margin: 0 0 15px;
    padding: 0 15px; }
    dl dd > :first-child {
      margin-top: 0; }
    dl dd > :last-child {
      margin-bottom: 0; }

blockquote {
  border-left: 4px solid #dddddd;
  padding: 0 15px;
  color: #777777; }
  blockquote > :first-child {
    margin-top: 0; }
  blockquote > :last-child {
    margin-bottom: 0; }

table {
  padding: 0;border-collapse: collapse; }
  table tr {
    border-top: 1px solid #cccccc;
    background-color: white;
    margin: 0;
    padding: 0; }
    table tr:nth-child(2n) {
      background-color: #f8f8f8; }
    table tr th {
      font-weight: bold;
      border: 1px solid #cccccc;
      margin: 0;
      padding: 6px 13px; }
    table tr td {
      border: 1px solid #cccccc;
      margin: 0;
      padding: 6px 13px; }
    table tr th :first-child, table tr td :first-child {
      margin-top: 0; }
    table tr th :last-child, table tr td :last-child {
      margin-bottom: 0; }

img {
  max-width: 100%; }

span.frame {
  display: block;
  overflow: hidden; }
  span.frame > span {
    border: 1px solid #dddddd;
    display: block;
    float: left;
    overflow: hidden;
    margin: 13px 0 0;
    padding: 7px;
    width: auto; }
  span.frame span img {
    display: block;
    float: left; }
  span.frame span span {
    clear: both;
    color: #333333;
    display: block;
    padding: 5px 0 0; }
span.align-center {
  display: block;
  overflow: hidden;
  clear: both; }
  span.align-center > span {
    display: block;
    overflow: hidden;
    margin: 13px auto 0;
    text-align: center; }
  span.align-center span img {
    margin: 0 auto;
    text-align: center; }
span.align-right {
  display: block;
  overflow: hidden;
  clear: both; }
  span.align-right > span {
    display: block;
    overflow: hidden;
    margin: 13px 0 0;
    text-align: right; }
  span.align-right span img {
    margin: 0;
    text-align: right; }
span.float-left {
  display: block;
  margin-right: 13px;
  overflow: hidden;
  float: left; }
  span.float-left span {
    margin: 13px 0 0; }
span.float-right {
  display: block;
  margin-left: 13px;
  overflow: hidden;
  float: right; }
  span.float-right > span {
    display: block;
    overflow: hidden;
    margin: 13px auto 0;
    text-align: right; }

code, tt {
  margin: 0 2px;
  padding: 0 5px;
  white-space: nowrap;
  border: 1px solid #eaeaea;
  background-color: #f8f8f8;
  border-radius: 3px; }

pre code {
  margin: 0;
  padding: 0;
  white-space: pre;
  border: none;
  background: transparent; }

.highlight pre {
  background-color: #f8f8f8;
  border: 1px solid #cccccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px; }

pre {
  background-color: #f8f8f8;
  border: 1px solid #cccccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px; }
  pre code, pre tt {
    background-color: transparent;
    border: none; }

sup {
    font-size: 0.83em;
    vertical-align: super;
    line-height: 0;
}

kbd {
  display: inline-block;
  padding: 3px 5px;
  font-size: 11px;
  line-height: 10px;
  color: #555;
  vertical-align: middle;
  background-color: #fcfcfc;
  border: solid 1px #ccc;
  border-bottom-color: #bbb;
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 #bbb
}

* {
	-webkit-print-color-adjust: exact;
}
@media screen and (min-width: 914px) {
    body {
        width: 854px;
        margin:0 auto;
    }
}
@media print {
	table, pre {
		page-break-inside: avoid;
	}
	pre {
		word-wrap: break-word;
	}
}
</style>


</head>

<body>

<h1 id="toc_0">Getting into Top 5% on Kaggle</h1>

<p>This post records my experience in Kaggle&#39;s <em><a href="https://www.kaggle.com/c/allstate-claims-severity">Allstate Claims Severity</a></em> competition. It has three parts—feel free to skip to whichever you&#39;re interested in!</p>

<ul>
<li><a href="#intro">Self-Introduction</a></li>
<li><a href="#reflect">Candid Reflections on the Competition</a></li>
<li><a href="#start">Things I have learnt</a></li>
</ul>

<hr>

<p><a name="intro"></a></p>

<h3 id="toc_1">Self-Introduction</h3>

<p>Hello! I am Yi Xiang, currently employed as a Junior Data Scientist. Feel free to drop me a message if you think I can improve in any way! You can reach me at my <a href="https://www.linkedin.com/in/yi-xiang-low-b349137b">LinkedIn</a>.</p>

<p>In the many meet-ups I have attended, a common question that aspiring data scientists ask employers is:</p>

<div><pre><code class="language-none">What do you look for in a potential hire? </code></pre></div>

<p>Typical answers would include:</p>

<div><pre><code class="language-none">* Communication or storytelling skills
* Coding proficiency
* Learning ability
* Passion
* And the lists goes on...</code></pre></div>

<p>Upon hearing this, the follow-up question usually most likely be:</p>

<div><pre><code class="language-none"> How should I demonstrate this to my potential employer?</code></pre></div>

<p>And the advice given is usually to: </p>

<div><pre><code class="language-none">* Increase online presence (e.g. through github, blogs)
* Find interesting projects to work on</code></pre></div>

<p>The truth is, I had procrastinated on fulfilling the above two points, and it was time I did something about it. Kaggle seemed like a good fit for the above two objectives. That was how I joined the Allstate Claims Severity competition on 2nd nov, which lasted from Oct to Dec 2016.  </p>

<hr>

<p><a name="reflect"></a></p>

<h3 id="toc_2">Candid Reflections on the Competition</h3>

<p>Among those familiar with this field, <a href="http://xgboost.readthedocs.io/">xgboost</a> (XGB) comes to mind as a popular approach to <strong>ANY</strong> (structured) machine learning problem. </p>

<p>Hence, I started the competition with an initial goal of learning how to tune XGB, and this was how my goals evolved during the competition over a single month: </p>

<ol>
<li>Squeezed into the top 10% by tuning XGB, thus decided an attempt to achieve a bronze medal (top 10%). </li>
<li>Within no time at all, I was kicked out of the top 10%. In order to climb back up, I had to ensemble different models. Most people in the forums had recommended ensembling neural nets with XGB. Unfortunately, apart from learning about it Coursera, I had no experience with neural nets!</li>
<li>Neural nets are <strong>very</strong> slow on CPU. To speed things up, I learnt to set up CUDA on an AWS GPU-compute series, install python and Theano, transfer data, and to configure a Juypter notebook! </li>
<li>With my neural net and XGB, a simple average got me into the top 5% - great! Let&#39;s attempt to win a sliver medal instead (top 5%).</li>
<li>Unfortunately, within no time at all, I was almost kicked out (again) of the top 5%, and there was a risk I might drop further down the private leaderboard due to overfitting.</li>
<li>Time for stacking! I understood the concept, but I have never done it before. Sadly, I did not extract my out-of-bag predictions from previous models (a painful but important lesson). I tried XGB and ridge regression for a second level modelling, which yielded lousy results. This was when I nearly hit a roadblock and thought I might have to settle for being in the top 10%.</li>
<li>Just then, someone posted about using neural nets as a second level model close to the last day. In a last burst of fire, I decided to give it a shot—and it worked! I was ranked 78th on the public leaderboard and 46th on the private leaderboard, which was really a surprise! </li>
</ol>

<p>The point i am trying to make is that:</p>

<div><pre><code class="language-none">Kaggle is really a good place to start with lots of helpful people sharing.</code></pre></div>

<h3 id="toc_3">Therefore, my objective for publishing this post is to:</h3>

<ol>
<li>Share about my experience, learnings! </li>
<li>Document my code! </li>
<li>Encourage aspiring data scientists to start! </li>
</ol>

<hr>

<p><a name="start"></a></p>

<p><a href="https://www.kaggle.com/c/allstate-claims-severity" target="_blank"><img src="https://www.allstatenewsroom.com/wp-content/uploads/2015/12/Allstate_Logo4.jpeg" width="400"></a></p>

<h1 id="toc_4">Aim of Competition</h1>

<p>The aim of this competition was to create an algorithm to predict the severity of insurance claims. Evaluation metric used was the <em><a href="https://www.kaggle.com/wiki/MeanAbsoluteError">Mean Absolute Error (MAE)</a></em>. </p>

<p>If you wish to reproduce my results, refer to the <code>README.md</code> <a href="https://github.com/Freedom89/Allstate_kaggle">here</a>. </p>

<h2 id="toc_5">Contents</h2>

<ol>
<li><a href="#custom">Custom Objectives</a></li>
<li><a href="#xgbfir">Finding Interactions, Encoding, Boxcox</a></li>
<li><a href="#Tune">Tuning XGB</a></li>
<li><a href="#NN">Neural Networks</a></li>
<li><a href="#ensemble1">Ensemble Version 1</a></li>
<li><a href="#ensemble2">Ensemble with Weighted Average</a></li>
<li><a href="#ensemble3">Ensemble with NN</a></li>
<li><a href="#reflections">Things I should/would have tried</a></li>
</ol>

<h4 id="toc_6"><a name="custom"></a>Custom Objectives</h4>

<hr>

<p>My (current) understanding about MSE is that it penalises error that are further away from the mean, while MAE penalises errors equally. The first thing I learnt about the <a href="http://www.vanguardsw.com/business-forecasting-101/mean-absolute-deviation-mad-mean-absolute-error-mae/">MAE</a> metric was that it optimises in terms of the median value, while MSE optimises for the mean. More information  <a href="http://stats.stackexchange.com/questions/147001/is-minimizing-squared-error-equivalent-to-minimizing-absolute-error-why-squared">here</a>.</p>

<p>If you had taken undergraduate mathematics, you would know that <code>y = |x|</code> is non-differentiable at <code>x = 0</code>. So when you configure Xgboost to use <code>eval_metric = &#39;mae&#39;</code>, the <a href="http://stackoverflow.com/questions/34178287/difference-between-objective-and-feval-in-xgboost">algorithm would still descent by MSE</a>, which poses a problem if you are optimising for MAE. To avoid over-penalising values further away from the mean, you could compress the range of values of your target variable, such as normalising, scaling or log-transform, but it still would not solve the problem. </p>

<p>However, it turned out that numerical approximation is very useful (thank you taylor series!). This <a href="http://research.microsoft.com/en-us/um/people/zhang/INRIA/Publis/Tutorial-Estim/node24.html">link</a> (<strong>worth reading!</strong>) describes the intuition behind optimising for MAE. For those who did undergraduate mathematics/statistics, you would remember functions like Cauchy and huber, which happens to be solvers for MAE problems. More information <a href="http://scipy-cookbook.readthedocs.io/items/robust_regression.html">here</a>.</p>

<p>Basically,  This is done via the &#39;Fair&#39; objective function. Essentially, you define an MAE objective function, but with a the gradient (first derivative) and hessian (second derivative) of the <code>Fair objective Function</code>. </p>

<p>Below, you can observe how the &#39;Fair&#39; objective function mimics the least-absolute function pretty accurately:</p>

<p><img src="http://research.microsoft.com/en-us/um/people/zhang/INRIA/Publis/Tutorial-Estim/img334.gif" width="400"></p>

<p>The objective, gradient, hessian of the above functions are defined as follows:</p>

<p><img src="http://research.microsoft.com/en-us/um/people/zhang/INRIA/Publis/Tutorial-Estim/img333.gif" width="400"></p>

<p>Majority of the scripts in the forums used the &#39;Fair&#39; objective, coded as: </p>

<div><pre><code class="language-none">def fair_obj(preds, dtrain):
    fair_constant = 2
    labels = dtrain.get_label()
    x = (preds - labels)
    den = abs(x) + fair_constant
    grad = fair_constant * x / (den)
    hess = fair_constant * fair_constant / (den * den)
    return grad, hess</code></pre></div>

<p>The smaller <code>fair_constant</code> is, the <em>slower</em> or <em>smoother</em> the loss is. </p>

<p>This custom objective can then be used in <code>xgb.train</code>:</p>

<div><pre><code class="language-none">clf = xgb.train(params,
                d_train,
                100000,
                watchlist,
                early_stopping_rounds=early_stop,
                obj=fair_obj,
                verbose_eval = n_print,
                feval=xg_eval_mae)</code></pre></div>

<p>Additional information can be found <a href="https://www.kaggle.com/c/allstate-claims-severity/forums/t/24520/effect-of-mae">here</a>.</p>

<h4 id="toc_7"><a href="#start">Back to contents</a></h4>

<h4 id="toc_8"><a name="xgbfir"></a>Finding Interactions, Encoding, Boxcox</h4>

<hr>

<h5 id="toc_9">Finding Interactions</h5>

<p>One of the limitations of linear regression is in identifying interactions between features. To solve this, an <a href="https://github.com/Far0n/xgbfi">XGBoost model dump parser</a> was developed as a way to find N-way feature interactions that can be used to improve your XGB model, or to be used as features themselves. </p>

<p>Fortunately, someone else posted <a href="https://www.kaggle.com/modkzs/allstate-claims-severity/lexical-encoding-feature-comb/discussion">this script</a>, which saved me a bit of time on finding N-way feature interactions. </p>

<h5 id="toc_10">Encoding</h5>

<p>In the raw data, features ran from <code>A, B, ... , Z,</code> to <code>AA, .. AZ</code>, which seemed to suggest some significance in how the data was ordered.</p>

<p>Therefore, instead of using label or one hot encoding, I experimented with an alternative function to encode these categorical features:</p>

<div><pre><code class="language-none">def encode(charcode):
    r = 0
    ln = len(str(charcode))
    for i in range(ln):
        r += (ord(str(charcode)[i]) - ord(&#39;A&#39;) + 1) * 26 ** (ln - i - 1)
    return r
    </code></pre></div>

<p>Essentially, this function recodes categories based on their rank order:</p>

<ul>
<li><code>encode(&#39;A&#39;)   = 1</code></li>
<li><code>encode(&#39;Z&#39;)   = 26</code></li>
<li><code>encode(&#39;AA&#39;)  = 27</code></li>
<li><code>encode(&#39;AC&#39;)  = 29</code></li>
</ul>

<p>While this method could be used to complement other functions like <code>min/max/mean/counts/ti-idf</code> , I did not manage to test this. </p>

<h5 id="toc_11">Boxcox</h5>

<p>Some machine learning algorithms perform better when features are normally distributed. Unfortunately, figuring out how to transform each feature as such requires a huge effort.</p>

<p>Introducing <em>boxcox</em>, a (very) convenient way of transforming these features by measuring their <a href="https://en.wikipedia.org/wiki/Skewness">skew</a>.</p>

<p>Here are a couple of good articles explaining boxcox that I came across:</p>

<ul>
<li><a href="https://www.isixsigma.com/tools-templates/normality/making-data-normal-using-box-cox-power-transformation/">Fairly Layman</a></li>
<li><a href="http://onlinestatbook.com/2/transformations/box-cox.html">Math and more Math</a>—never thought year one calculus would be this useful!</li>
</ul>

<p>Implementing boxcox in code:</p>

<div><pre><code class="language-none">skewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna()))
skewed_feats = skewed_feats[abs(skewed_feats) &gt; 0.25]
skewed_feats = skewed_feats.index

for feats in skewed_feats:
    train_test[feats] = train_test[feats] + 1
    train_test[feats], lam = boxcox(train_test[feats])
</code></pre></div>

<h4 id="toc_12"><a href="#start">Back to contents</a></h4>

<h4 id="toc_13"><a name="Tune"></a>Tuning XGB</h4>

<hr>

<p>Unless you are extremely experienced and have good intuition about which parameter values to use, it is likely that you need to learn from trial and error. </p>

<p>For this, I recommend <a href="https://github.com/hyperopt/hyperopt">hyperopt</a>, a python library for serial and parallel optimisation over awkward search spaces. It even allows you to tweak the number of layers in a neural net! </p>

<p>I have some examples in my git repo:</p>

<ul>
<li><p><a href="https://github.com/Freedom89/Allstate_kaggle/blob/master/hyperopt_results/hyper_opt_xgb.ipynb">XGB</a></p>

<p>Change the data input to power3 if you want to run hyperopt for a 3-way interaction</p></li>
<li><p><a href="https://github.com/Freedom89/Allstate_kaggle/blob/master/hyperopt_results/extratrees_hyper_opt.ipynb">Extra Trees</a></p></li>
<li><p><a href="https://github.com/Freedom89/Allstate_kaggle/blob/master/hyperopt_results/hyper_opt_random_forest.ipynb">Random Forest</a></p></li>
</ul>

<p>Results of the hyperopt can be found in <a href="https://github.com/Freedom89/Allstate_kaggle/tree/master/hyperopt_results">this repo</a>.</p>

<h4 id="toc_14"><a href="#start">Back to contents</a></h4>

<h4 id="toc_15"><a name="NN"></a>Neural Networks</h4>

<hr>

<p>As mentioned, this is my first time coding a neural net outside of Coursera (<a href="https://www.coursera.org/learn/machine-learning">Andrew Ng&#39;s Machine Learning</a> and <a href="https://www.coursera.org/specializations/machine-learning">UOW&#39;s Machine Learning specialisation</a>).</p>

<h5 id="toc_16">Using AWS</h5>

<p><a href="https://www.kaggle.com/mtinti/allstate-claims-severity/keras-starter-with-bagging-1111-84364/comments">This script</a> helped me a lot in starting out with neural networks, but running it on an 8-core MacBook pro would have taken at least 2 days (55 runs * 30 seconds * 10 fold * 10 bags = 45 hours)!</p>

<p>With all the hype over cloud computing, I decided to give AWS GPU-compute series spot instances a go, which was about 0.35 cents per hour. While there are plenty of online resources about how to implement this, they are not without missing pieces. </p>

<p>I will write a guide on installing Anaconda, Juypter, Cudas, Keras and Theano in a separate post soon. </p>

<p>For those who are starting out with Keras like me, there are two things you must note: </p>

<p>In your home directory, run the following:</p>

<div><pre><code class="language-none">cd .keras/
nano keras.json #use open/subl depending on your OS </code></pre></div>

<p>You should see:</p>

<div><pre><code class="language-none">{
    &quot;image_dim_ordering&quot;: &quot;tf&quot;, 
    &quot;epsilon&quot;: 1e-07, 
    &quot;floatx&quot;: &quot;float32&quot;, 
    &quot;backend&quot;: &quot;Tensorflow&quot;
}</code></pre></div>

<p>If you want to use Theano, you have to edit <code>Tensorflow</code> to <code>Theano</code></p>

<div><pre><code class="language-none">{
    &quot;image_dim_ordering&quot;: &quot;tf&quot;, 
    &quot;epsilon&quot;: 1e-07, 
    &quot;floatx&quot;: &quot;float32&quot;, 
    &quot;backend&quot;: &quot;theano&quot;
}</code></pre></div>

<p>If you are using an Nvidia GPU, installing Theano would introduce a <code>.theanorc</code> file in your home directory. If it&#39;s not there, you need to create one and paste the following inside: </p>

<div><pre><code class="language-none">[global]
floatX = float32
device = gpu
[mode] = FAST_RUN

[nvcc]
fastmath=TRUE

[cuda]
root = /usr/local/cuda

[lib]
cnmem = 0.95</code></pre></div>

<p>The line <code>cnmem = 0.95</code> is very important—it halves the duration of each iteration from 12 to 6 seconds!</p>

<h5 id="toc_17">Print Validation Loss and Early Stopping</h5>

<p>To see monitor whether your score is improving and to determine early stopping, you need to first specify the metric function:</p>

<div><pre><code class="language-none">def mae(y_true, y_pred):
    return K.mean(K.abs(K.exp(y_true) - K.exp(y_pred)))</code></pre></div>

<p>and put it inside the <code>keras.compile</code> function:</p>

<div><pre><code class="language-none">model.compile(loss = &#39;mae&#39;, optimizer = optimizer, metrics=[mae])
</code></pre></div>

<p>Use this code to determine early stopping and checkpoints for your model:</p>

<div><pre><code class="language-none">callsback_list = [EarlyStopping(patience=10),
                  ModelCheckpoint(&#39;keras-regressor-&#39; + str(i+1) +&#39;_&#39;+ str(j+1) + &#39;.check&#39;\
                                  , monitor=&#39;val_loss&#39;, save_best_only=True, verbose=0)]</code></pre></div>

<p>Then, specify the <code>validation_data</code> and <code>callsback</code>:</p>

<div><pre><code class="language-none">fit = model.fit_generator(generator = batch_generator(xtr, ytr, 128, True),
                                  nb_epoch = nepochs,
                                  samples_per_epoch = xtr.shape[0],
                                  verbose = 0,
                                  validation_data=(xte.todense(),yte),
                                  callbacks=callsback_list)</code></pre></div>

<p>where <code>xtr, ytr</code> is the training set, and <code>xte, yte</code> the validation set in the specified <code>Kfold</code>. </p>

<p>You can then call the best model with <code>val_loss</code> or <code>val_mae</code>, before making the best prediction with:</p>

<div><pre><code class="language-none">fit = load_model(&#39;keras-regressor-&#39; + str(i+1) + &#39;_&#39;+ str(j+1) + &#39;.check&#39;)
    
pred += np.exp(fit.predict_generator(generator = batch_generatorp(xte, 800, False), \
                                       val_samples = xte.shape[0])[:,0])-200</code></pre></div>

<h5 id="toc_18">Spoiler alert!</h5>

<p>To see how I used early stopping for my second level modelling, check out <a href="https://github.com/Freedom89/Allstate_kaggle/blob/master/second_level_models/keras_stacking_single_fold.ipynb">this link</a>. Turns out that saving the model is a good idea if you want to use it later on. You can try it by commenting out the following lines from the notebook:</p>

<div><pre><code class="language-none">#comment from here 
callsback_list = [EarlyStopping(patience=10),\
          ModelCheckpoint(&#39;keras-regressor-&#39; + str(i+1) +&#39;_&#39;+ str(j+1) + &#39;.check&#39;\
                          , monitor=&#39;val_loss&#39;, save_best_only=True, verbose=0)]
    
model = nn_model(layer1=250,layer2=100,\
     dropout1 = 0.4,dropout2=0.2, \
     optimizer = &#39;adadelta&#39;)
    
fit = model.fit_generator(generator = batch_generator(xtr, ytr, 128, True),
                          nb_epoch = nepochs,
                          samples_per_epoch = xtr.shape[0],
                          verbose = 0,
                          validation_data=(xte.todense(),yte),
                          callbacks=callsback_list)
    
# to here if you just want to use the pre-trained models yourself.</code></pre></div>

<h4 id="toc_19"><a href="#start">Back to contents</a></h4>

<h4 id="toc_20"><a name="ensemble1"></a>Ensemble Version 1</h4>

<hr>

<p>After training my neural networks, I randomly assigned weights to my best XGB and Keras predictions to see which would fit the public leaderboard best. </p>

<p>When I decided to do stacking, I started reading up:</p>

<ul>
<li><a href="http://mlwave.com/kaggle-ensembling-guide/">Here</a></li>
<li><a href="https://www.kaggle.com/mmueller/allstate-claims-severity/stacking-starter/run/390867/code">Here</a></li>
<li><a href="https://www.kaggle.com/c/allstate-claims-severity/forums/t/25743/stacking-understanding-python-package-for-stacking">And here</a></li>
</ul>

<p>I did not have any of my out-of-bag (OOB) training sets. This meant that I had to re-write my codes and retrain the models. <strong>Lesson Learnt: You should always extract the OOB sets for models running on <em>k</em>-fold validation even if you are unsure stacking is required.</strong></p>

<h5 id="toc_21">XGB example (pseudo code)</h5>

<div><pre><code class="language-none">pred_oob = np.zeros(train_x.shape[0])

for iterations in kfold:
    #split training and test set 
    scores_val = clf.predict(d_valid, ntree_limit=clf.best_ntree_limit)
    pred_oob[test_index] = np.exp(scores_val) - shift

#export the oob training set
oob_df = pd.DataFrame(pred_oob, columns = [&#39;loss&#39;])
sub_file = &#39;oob_xgb_fairobj_&#39; + str(score) + &#39;_&#39; + str(
    now.strftime(&quot;%Y-%m-%d-%H-%M&quot;)) + &#39;.csv&#39;
print(&quot;Writing submission: %s&quot; % sub_file)
oob_df.to_csv(sub_file, index = False)   
</code></pre></div>

<p>This concept would apply to other models as well. </p>

<p>Additionally, if you are using AWS, disconnections to your juypter kernels might disrupt tracking of your code progress (e.g which fold or bags it was running). I overcame this problem by adding these lines in my code:</p>

<p>For XGB:</p>

<div><pre><code class="language-none">partial_evalutaion = open(&#39;temp_scores_power2.txt&#39;,&#39;a&#39;) 

partial_evalutaion.write(&#39;Fold &#39;+ str(i) + &#39;- MAE:&#39;+ str(cv_score)+&#39;\n&#39;)

partial_evalutaion.flush()</code></pre></div>

<p>For hyperopt:</p>

<div><pre><code class="language-none">partial_evalutaion = open(&#39;extra_trees_bootstrap2.txt&#39;,&#39;a&#39;)   

partial_evalutaion.write(&#39;iteration &#39; + str(space) +str(iter_count) + &#39;with&#39; + &#39; &#39; + str(score) + &#39;\n&#39;)
partial_evalutaion.flush()</code></pre></div>

<p>To store all the parameters that ran on hyperopt, you can specify a data frame and call it within the function to append the results:</p>

<div><pre><code class="language-none">Df_results = pd.DataFrame() 

def objective(space):
    ...
    ...
    global Df_results
    Df_results = Df_results.append(log_files_df)
   
   return(...)
   
Df_results.to_csv(&quot;results.csv&quot;,index = None) 
 </code></pre></div>

<h4 id="toc_22"><a href="#start">Back to contents</a></h4>

<h4 id="toc_23"><a name="ensemble2"></a>Ensemble with Weighted Average</h4>

<hr>

<p>The idea for using a weighted average (in my opinion) stems from linear programming. Credit should go to <a href="https://www.kaggle.com/tilii7/allstate-claims-severity/ensemble-weights-minimization-vs-mcmc/comments">this post</a> for sharing the code on finding optimal weights. </p>

<p>To implement this,</p>

<ul>
<li>Bind all your OOB-training set together, then</li>
<li><p>Define the objective function as follows:</p>

<div><pre><code class="language-none">def mae_func(weights):
&#39;&#39;&#39; scipy minimize will pass the weights as a numpy array &#39;&#39;&#39;
final_prediction = 0
for weight, prediction in zip(weights, predictions):
        final_prediction += weight*prediction

return mean_absolute_error(Y_values, final_prediction)
</code></pre></div></li>
<li><p>After which, run the following code:</p>

<div><pre><code class="language-none">for i in range(100):
starting_values = np.random.uniform(size=len(predictions))
cons = ({&#39;type&#39;:&#39;ineq&#39;,&#39;fun&#39;:lambda w: 1.2-sum(w)})
bounds = [(0,1)]*len(predictions)

res = minimize(mae_func, starting_values, method=&#39;L-BFGS-B&#39;,
               bounds=bounds, options={&#39;disp&#39;: False, &#39;maxiter&#39;: 10000})

lls.append(res[&#39;fun&#39;])
wghts.append(res[&#39;x&#39;])

bestSC = np.min(lls)
bestWght = wghts[np.argmin(lls)]
</code></pre></div></li>
</ul>

<p>For those familiar with linear programming, you would understand that</p>

<p><code>cons = ({&#39;type&#39;:&#39;ineq&#39;,&#39;fun&#39;:lambda w: 1.2-sum(w)}</code> </p>

<p>implies that the sum of weights should not be greater than 1.2, while </p>

<p><code>bounds = [(0,1)]*len(predictions)</code> </p>

<p>implies that each weight should be between <code>0</code> and <code>1</code>.</p>

<p>With 6 XGB models and 4 Keras model, I generated <a href="https://github.com/Freedom89/Allstate_kaggle/blob/master/allstate1117.71816974.csv">this result</a>, which would have ranked me at 102th on the private leaderboard. The local CV score was about <code>1118.34</code> .</p>

<h4 id="toc_24"><a href="#start">Back to contents</a></h4>

<h4 id="toc_25"><a name="ensemble3"></a>Ensemble with NN</h4>

<hr>

<p><a href="https://www.kaggle.com/c/allstate-claims-severity/forums/t/26359/is-stacking-working-better-than-weighted-average-for-you?forumMessageId=149495#post149495">This post</a> inspired me to try neural networks as my second level model. </p>

<p>I must also admit I was pretty lucky in my first guess of parameters of a two layer NN with 250-100 nodes, found <a href="https://github.com/Freedom89/Allstate_kaggle/blob/master/second_level_models/keras_stacking_single_fold.ipynb">here</a>. My 5-fold approach generated the following results:</p>

<div><pre><code class="language-none">(&#39;Fold &#39;, 1, &#39;- MAE:&#39;, 1117.5260825665521)
(&#39;Fold &#39;, 2, &#39;- MAE:&#39;, 1113.2272453103922)
(&#39;Fold &#39;, 3, &#39;- MAE:&#39;, 1117.1135764027533)
(&#39;Fold &#39;, 4, &#39;- MAE:&#39;, 1121.9982577768997)
(&#39;Fold &#39;, 5, &#39;- MAE:&#39;, 1119.6595219061744)
(&#39;Total - MAE:&#39;, 1117.9049057391971)</code></pre></div>

<p>Interestingly, I tried 10 folds but obtained a worse CV result than <code>1118.34</code> (although it might not have meant a worse LB). </p>

<p>Afterwards, I decided to bag my model 5 times :</p>

<div><pre><code class="language-none">(&#39;Fold &#39;, 1, &#39;- MAE:&#39;, 1117.6329549570657)
(&#39;Fold &#39;, 2, &#39;- MAE:&#39;, 1113.3701316951469)
(&#39;Fold &#39;, 3, &#39;- MAE:&#39;, 1117.1293409206548)
(&#39;Fold &#39;, 4, &#39;- MAE:&#39;, 1121.8204992333194)
(&#39;Fold &#39;, 5, &#39;- MAE:&#39;, 1119.4491190596229)
(&#39;Total - MAE:&#39;, 1117.880379920515)</code></pre></div>

<p>You can see the entire output <a href="https://github.com/Freedom89/Allstate_kaggle/blob/master/second_level_models/keras_stacking_bagged.ipynb">here</a>.</p>

<p>However, the score was only 0.02 points better. Hence, I decided to weigh them with my best first level models, and tried the following submissions on the <strong>last day</strong>:</p>

<table>
<thead>
<tr>
<th style="text-align: left"></th>
<th style="text-align: left">Single 5 fold Keras</th>
<th style="text-align: left">W. avg with single fold NN</th>
<th style="text-align: left">Bagged 5 fold Keras</th>
<th style="text-align: left">W.avg with lvl 1 models with both NN</th>
</tr>
</thead>

<tbody>
<tr>
<td style="text-align: left">Local CV</td>
<td style="text-align: left">1117.90490574</td>
<td style="text-align: left">1117.77760897</td>
<td style="text-align: left">1117.88037992</td>
<td style="text-align: left">1117.7181697</td>
</tr>
<tr>
<td style="text-align: left">Public LB</td>
<td style="text-align: left">1100.90013</td>
<td style="text-align: left">1100.87763</td>
<td style="text-align: left">1100.88155</td>
<td style="text-align: left">1100.86946</td>
</tr>
<tr>
<td style="text-align: left">Private LB</td>
<td style="text-align: left">1112.84611</td>
<td style="text-align: left">1112.77244</td>
<td style="text-align: left">1112.93370</td>
<td style="text-align: left">1112.73936</td>
</tr>
</tbody>
</table>

<p>Surprisingly, the single 5-fold model performed better in the private LB than the bagged model. </p>

<p>The final weighted scores, codes and datasets I used can be found <a href="https://github.com/Freedom89/Allstate_kaggle/blob/master/fmin_second_level.ipynb">here</a>. </p>

<h4 id="toc_26"><a href="#start">Back to contents</a></h4>

<h4 id="toc_27"><a name="reflections"></a>Things I should/would have tried</h4>

<hr>

<ol>
<li>Shuffle the datasets by binning the target—my <em>k</em>-fold CV results were pretty inconsistent</li>
<li>Train specific models for high values of the dataset</li>
<li>Bagging with other datasets, as well as other forms of feature engineering </li>
<li>Further explore second level modelling, e.g. using a weighted average with only second level models</li>
</ol>

<p>Here are additional links to top solutions:</p>

<ul>
<li><a href="https://www.kaggle.com/c/allstate-claims-severity/forums/t/26416/1st-place-solution">1st place</a></li>
<li><a href="https://www.kaggle.com/c/allstate-claims-severity/forums/t/26427/2nd-place-solution">2nd place</a></li>
<li><a href="https://www.kaggle.com/c/allstate-claims-severity/forums/t/26447/faron-s-3rd-place-solution">3rd place</a></li>
<li><a href="https://www.kaggle.com/c/allstate-claims-severity/forums/t/26537/giba-7-place-solution">7th place</a></li>
<li><a href="https://www.kaggle.com/c/allstate-claims-severity/forums/t/26440/8-solution">8th place</a></li>
<li><a href="https://www.kaggle.com/c/allstate-claims-severity/forums/t/26414/12th-place-solution">12th place</a></li>
<li><a href="https://www.kaggle.com/c/allstate-claims-severity/forums/t/26430/16-place-solution-and-some-questions-about-it">16th place</a></li>
</ul>

<h4 id="toc_28"><a href="#start">Back to contents</a></h4>

<h1 id="toc_29">Thanks For Reading!</h1>




</body>

</html>
